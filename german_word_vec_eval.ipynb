{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out German wordvectors from Spacy and other sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results as of 31-05-2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('de_core_news_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking out the word vector for 'Katze'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Katze True 1.5040343 False\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(\"Katze\")\n",
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.94400e-02,  6.50390e-02,  3.84020e-02,  5.71960e-02,\n",
       "       -1.07483e-01,  9.44500e-02,  1.26056e-01, -3.67150e-02,\n",
       "       -5.19510e-02,  5.70890e-02, -3.57100e-03, -1.54680e-01,\n",
       "       -1.79570e-01,  1.22324e-01,  2.95920e-02, -1.52795e-01,\n",
       "        1.75330e-02,  2.72260e-02, -3.26880e-02, -5.72130e-02,\n",
       "        7.61460e-02, -1.15061e-01, -1.18281e-01,  6.27390e-02,\n",
       "        5.73380e-02,  8.77280e-02, -4.46090e-02, -7.46910e-02,\n",
       "        6.35170e-02,  6.42840e-02,  5.79190e-02, -1.95661e-01,\n",
       "       -3.66710e-02,  1.02721e-01, -1.22134e-01,  1.80000e-03,\n",
       "        5.61740e-02,  6.45820e-02, -1.47540e-02, -1.47828e-01,\n",
       "       -3.81200e-02, -1.64022e-01, -6.24050e-02,  5.61530e-02,\n",
       "        1.64387e-01,  6.80460e-02,  1.80591e-01, -2.91230e-02,\n",
       "        4.31600e-03,  1.40180e-02,  4.37030e-02, -2.29150e-02,\n",
       "       -4.17530e-02, -7.53750e-02,  6.99130e-02, -6.91130e-02,\n",
       "        1.00700e-03,  2.34009e-01, -7.96400e-02,  7.47110e-02,\n",
       "        2.84470e-02,  5.21340e-02,  8.57650e-02, -5.56790e-02,\n",
       "       -4.64900e-02,  3.81810e-02,  6.47380e-02, -1.29101e-01,\n",
       "       -1.56267e-01,  1.19110e-01,  9.13850e-02,  8.93200e-02,\n",
       "       -8.16340e-02,  6.30740e-02, -6.76660e-02,  1.44070e-02,\n",
       "        2.12850e-02,  6.45240e-02,  1.04013e-01, -1.10746e-01,\n",
       "        7.95370e-02,  9.12460e-02,  2.14424e-01, -1.86394e-01,\n",
       "       -3.32400e-02,  3.80360e-02,  2.28990e-02,  3.01290e-02,\n",
       "        1.27513e-01,  2.01150e-02, -8.73650e-02, -2.94390e-02,\n",
       "        1.04930e-02,  6.57740e-02, -5.82160e-02,  1.02430e-01,\n",
       "        5.20330e-02, -4.48280e-02, -4.32990e-02,  5.27830e-02,\n",
       "       -3.58120e-02,  3.56700e-03,  1.16421e-01, -1.03810e-01,\n",
       "        7.15860e-02, -3.98730e-02,  2.21550e-02,  9.47300e-03,\n",
       "       -1.61150e-02,  5.92110e-02, -4.57710e-02,  2.12215e-01,\n",
       "       -7.81700e-03,  1.27402e-01,  3.76570e-02,  4.96750e-02,\n",
       "       -3.22000e-04, -1.08736e-01,  1.61344e-01,  2.27040e-02,\n",
       "        2.65000e-04, -1.33730e-02,  1.53199e-01, -2.50810e-02,\n",
       "       -2.31450e-02, -3.78900e-02, -1.05550e-02,  6.61260e-02,\n",
       "        1.67620e-02, -5.39610e-02, -3.13320e-02, -1.29229e-01,\n",
       "       -3.12710e-02, -6.54810e-02, -1.75542e-01,  8.23610e-02,\n",
       "        1.14890e-01, -8.59150e-02, -1.57450e-01,  4.48600e-02,\n",
       "        3.01070e-02, -5.51700e-03,  7.71510e-02, -1.25573e-01,\n",
       "       -3.41530e-02, -1.87370e-02, -4.48060e-02, -2.08440e-01,\n",
       "        3.86480e-02,  1.50090e-02, -8.72390e-02, -8.45460e-02,\n",
       "        5.78400e-03, -3.45590e-02,  2.46650e-02,  3.33870e-02,\n",
       "        9.68320e-02,  5.29000e-04, -4.87640e-02,  5.39810e-02,\n",
       "        2.84190e-02,  1.02709e-01,  7.16530e-02, -1.69800e-02,\n",
       "        3.89000e-02,  6.90480e-02, -2.28250e-02, -1.45978e-01,\n",
       "        4.61200e-03,  1.73539e-01, -6.13550e-02, -4.75370e-02,\n",
       "        1.05050e-02,  3.25560e-02, -8.26090e-02, -1.61170e-02,\n",
       "        5.35960e-02,  6.60930e-02, -4.46100e-03, -7.47550e-02,\n",
       "       -5.04110e-02, -1.23754e-01,  1.57300e-02,  5.61170e-02,\n",
       "        1.32400e-01,  4.32780e-02, -1.09500e-03,  6.96900e-02,\n",
       "       -1.52421e-01, -1.24420e-02, -2.34530e-02,  2.37260e-02,\n",
       "        1.34260e-01, -1.72595e-01, -4.84140e-02,  1.14774e-01,\n",
       "       -9.03800e-02, -6.27800e-03,  1.07747e-01,  2.75050e-02,\n",
       "        7.67200e-03, -4.82220e-02, -7.80350e-02,  5.30300e-02,\n",
       "        2.93360e-01,  1.78423e-01, -8.51500e-02,  2.67010e-02,\n",
       "       -3.22610e-02, -7.19060e-02, -4.58380e-02, -5.10980e-02,\n",
       "        2.13910e-02,  7.12420e-02,  9.65300e-03, -1.20777e-01,\n",
       "        7.49580e-02, -2.06305e-01, -2.84380e-02, -3.81360e-02,\n",
       "        1.16445e-01, -7.28200e-03, -2.29360e-02, -1.50742e-01,\n",
       "       -4.68000e-04,  8.64350e-02,  1.26419e-01,  8.28500e-03,\n",
       "       -6.32380e-02, -5.42600e-03,  3.65060e-02, -9.94900e-02,\n",
       "        1.44484e-01,  1.32425e-01,  6.56670e-02,  1.72977e-01,\n",
       "       -1.45940e-02,  4.49140e-02,  1.88280e-02,  1.20493e-01,\n",
       "        1.44272e-01,  9.99400e-03,  8.76720e-02,  4.92210e-02,\n",
       "        1.01975e-01,  4.27350e-02,  2.33530e-02, -5.60460e-02,\n",
       "       -8.84690e-02, -1.19279e-01, -1.29071e-01, -7.41390e-02,\n",
       "       -1.22201e-01, -2.70170e-02, -7.82130e-02, -1.47625e-01,\n",
       "       -1.12532e-01,  3.59370e-02, -2.02580e-02,  7.84320e-02,\n",
       "       -7.21610e-02, -2.90960e-02,  4.99200e-03,  4.99600e-03,\n",
       "        1.34909e-01, -2.73480e-02,  4.08080e-02, -6.94440e-02,\n",
       "       -1.49137e-01, -4.94890e-02,  1.04991e-01, -1.04758e-01,\n",
       "        8.32030e-02,  6.80230e-02,  8.90320e-02, -4.89890e-02,\n",
       "        8.11840e-02, -1.16757e-01,  9.19600e-03,  6.74700e-02,\n",
       "        5.92200e-02, -3.72300e-02, -1.12154e-01,  4.72560e-02,\n",
       "       -8.14420e-02, -1.89260e-02, -7.91450e-02,  2.42010e-02,\n",
       "       -6.94800e-02, -4.03050e-02,  8.97130e-02, -8.19320e-02,\n",
       "       -2.36647e-01,  1.12787e-01,  5.05960e-02, -1.57800e-02,\n",
       "       -4.11970e-02, -1.07039e-01,  1.26944e-01, -3.58940e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's compare some vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = nlp(\"Mann Frau Banane Apfel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann Frau 0.49876732\n",
      "Mann Banane 0.40122947\n",
      "Mann Apfel 0.51279485\n",
      "Frau Mann 0.49876732\n",
      "Frau Banane 0.42747173\n",
      "Frau Apfel 0.5439015\n",
      "Banane Mann 0.40122947\n",
      "Banane Frau 0.42747173\n",
      "Banane Apfel 0.55466294\n",
      "Apfel Mann 0.51279485\n",
      "Apfel Frau 0.5439015\n",
      "Apfel Banane 0.55466294\n"
     ]
    }
   ],
   "source": [
    "for token1 in tokens:\n",
    "    for token2 in tokens:     \n",
    "        if token1 != token2:\n",
    "            print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems German women are more similar to apples than to men according to this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's the most similar word?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_similar(word):\n",
    "    queries = [w for w in word.vocab if w.is_lower == word.is_lower and w.prob >= -15 and w.has_vector]\n",
    "    by_similarity = sorted(queries, key=lambda w: word.similarity(w), reverse=True)\n",
    "    return by_similarity[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hund',\n",
       " 'engel',\n",
       " 'tur',\n",
       " 'nech',\n",
       " 'nis',\n",
       " 'nat',\n",
       " 'denne',\n",
       " 'enn',\n",
       " 'ene',\n",
       " 'hände',\n",
       " 'neh',\n",
       " 'flo',\n",
       " 'nä',\n",
       " 'hy',\n",
       " 'mord',\n",
       " 'hunden',\n",
       " 'igen',\n",
       " 'dig',\n",
       " 'jau',\n",
       " 'ju']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.lower_ for w in most_similar(nlp.vocab[u'hund'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apfel',\n",
       " 'mops',\n",
       " 'kohl',\n",
       " 'kuss',\n",
       " 'chr',\n",
       " 'schwanz',\n",
       " 'krankheit',\n",
       " 'schleim',\n",
       " 'elefanten',\n",
       " 'esel',\n",
       " 'trottel',\n",
       " 'knoblauch',\n",
       " 'koffer',\n",
       " 'schleier',\n",
       " 'mantel',\n",
       " 'schlitten',\n",
       " 'dreck',\n",
       " 'geruch',\n",
       " 'freude',\n",
       " 'werth']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.lower_ for w in most_similar(nlp.vocab[u'Apfel'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is it any better in English?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog',\n",
       " 'kennel',\n",
       " 'canine',\n",
       " 'hound',\n",
       " 'canines',\n",
       " 'dogs',\n",
       " 'puppy',\n",
       " 'poodle',\n",
       " 'terrier',\n",
       " 'husky',\n",
       " 'greyhound',\n",
       " 'retriever',\n",
       " 'pet',\n",
       " 'grooming',\n",
       " 'feline',\n",
       " 'cat',\n",
       " 'puppies',\n",
       " 'pitbulls',\n",
       " 'huskies',\n",
       " 'pitbull']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.lower_ for w in most_similar(nlp.vocab[u'dog'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple',\n",
       " 'blackberry',\n",
       " 'apples',\n",
       " 'pears',\n",
       " 'iphone',\n",
       " 'fruit',\n",
       " 'fig',\n",
       " 'strawberry',\n",
       " 'popsicle',\n",
       " 'icecream',\n",
       " 'ipad',\n",
       " 'kiwi',\n",
       " 'grapefruit',\n",
       " 'mango',\n",
       " 'pineapple',\n",
       " 'cider',\n",
       " 'mead',\n",
       " 'ipod',\n",
       " 'cranberry',\n",
       " 'pomegranate']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.lower_ for w in most_similar(nlp.vocab[u'apple'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = nlp(\"man woman banana apple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man woman 0.7401745\n",
      "man banana 0.2426803\n",
      "man apple 0.20974894\n",
      "woman man 0.7401745\n",
      "woman banana 0.2260633\n",
      "woman apple 0.19461377\n",
      "banana man 0.2426803\n",
      "banana woman 0.2260633\n",
      "banana apple 0.5831845\n",
      "apple man 0.20974894\n",
      "apple woman 0.19461377\n",
      "apple banana 0.5831845\n"
     ]
    }
   ],
   "source": [
    "for token1 in tokens:\n",
    "    for token2 in tokens:     \n",
    "        if token1 != token2:\n",
    "            print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's more like it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion German language model in Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't seem very impressive compared to the English one. Are there any better models available?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out German wordvectors from https://devmount.github.io/GermanWordEmbeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectors_model = KeyedVectors.load_word2vec_format('german.model', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01952714,  0.0331448 ,  0.05852811, -0.06965609, -0.31470928,\n",
       "        0.39255175, -0.14503856, -0.02480443, -0.29768062,  0.17916209,\n",
       "        0.00299389,  0.16924381,  0.02153021,  0.05605159, -0.38303784,\n",
       "        0.22865692, -0.28690276,  0.16789638,  0.16018285,  0.0944666 ,\n",
       "       -0.13439137, -0.07034101,  0.36826703, -0.20224169,  0.11887279,\n",
       "       -0.11946199, -0.07052661, -0.05839675,  0.05703048,  0.1431304 ,\n",
       "       -0.12603366,  0.15745148, -0.04769883, -0.04310802,  0.0388437 ,\n",
       "        0.09252485, -0.13361232,  0.05377932,  0.09278485,  0.22191218,\n",
       "       -0.29280597,  0.22656001, -0.0546908 ,  0.11347145,  0.0254037 ,\n",
       "       -0.12268334,  0.45216   ,  0.12394026,  0.03888717,  0.04726605,\n",
       "        0.15844122,  0.09545826, -0.17165002,  0.0130187 , -0.24803649,\n",
       "       -0.14646243, -0.05550057,  0.05950546, -0.15945338,  0.08621194,\n",
       "        0.34104365, -0.09479828, -0.10784826, -0.20649078, -0.03533724,\n",
       "        0.7011522 ,  0.00796406,  0.31761488,  0.26239318,  0.22848007,\n",
       "       -0.25214574, -0.01120117, -0.14150879,  0.15572368, -0.21006012,\n",
       "       -0.02862911,  0.04430659,  0.12956919,  0.20313765,  0.0084583 ,\n",
       "        0.19794886,  0.05773043,  0.08707058,  0.05590469,  0.30055547,\n",
       "        0.359948  , -0.09584834, -0.05793772,  0.04312148,  0.03946545,\n",
       "       -0.06556907,  0.164327  ,  0.04891893,  0.3677198 , -0.49729934,\n",
       "        0.19116187, -0.35352343, -0.05943558, -0.18448846,  0.17856544,\n",
       "        0.34945983, -0.09130552,  0.51617396,  0.1003742 , -0.13153102,\n",
       "        0.1374502 , -0.28519776, -0.31699333,  0.07014237,  0.5596233 ,\n",
       "        0.1702299 ,  0.241236  ,  0.24661385, -0.00849651,  0.08927655,\n",
       "       -0.2037919 , -0.18985358, -0.06103742, -0.27565166,  0.03668108,\n",
       "       -0.12906341, -0.33330476,  0.28067857,  0.11827821,  0.2823816 ,\n",
       "        0.07662281,  0.04586726, -0.01951429,  0.18223095,  0.15743206,\n",
       "        0.09902535, -0.01275481, -0.2401434 ,  0.14647235,  0.09098562,\n",
       "        0.19623402,  0.1460152 ,  0.10557307,  0.16939417, -0.08126002,\n",
       "       -0.22839892,  0.02140184,  0.09887271, -0.01146783,  0.09153082,\n",
       "        0.15992992, -0.05543998, -0.02077565,  0.0197099 , -0.1885562 ,\n",
       "       -0.15955926,  0.10157599,  0.25371817, -0.15603116,  0.2360192 ,\n",
       "        0.0488386 , -0.09098746,  0.14681476,  0.27793273,  0.00264799,\n",
       "       -0.15708652,  0.01805905,  0.222965  ,  0.06840416,  0.15474224,\n",
       "        0.11802773, -0.06673066,  0.12141337, -0.05989831, -0.16256352,\n",
       "       -0.10515562, -0.30874556, -0.23139799,  0.18453903, -0.01456055,\n",
       "        0.16852544,  0.26828212, -0.23003739,  0.32133475, -0.19826208,\n",
       "        0.07722006, -0.20059042,  0.12661517,  0.07433172,  0.0406124 ,\n",
       "       -0.18059132,  0.05893691, -0.12436045,  0.13609086, -0.0230736 ,\n",
       "       -0.05741361, -0.00566124,  0.3380806 ,  0.00509614, -0.04202156,\n",
       "        0.14604159, -0.11681174, -0.38494346, -0.08684732, -0.09085435,\n",
       "        0.18513381, -0.03873942,  0.14658332, -0.30406696, -0.00515989,\n",
       "        0.02106035, -0.2757901 ,  0.2157504 , -0.1106388 ,  0.23833582,\n",
       "       -0.01608178,  0.07177344,  0.03165002, -0.1278417 ,  0.28644004,\n",
       "        0.1043986 ,  0.05499455,  0.30717576,  0.12847891, -0.02525954,\n",
       "       -0.18009003, -0.20560515,  0.00670046,  0.03468265, -0.03413   ,\n",
       "        0.25356874,  0.28126195, -0.01274743, -0.06922864, -0.03340308,\n",
       "        0.45820716, -0.10306657,  0.21571611, -0.11963823,  0.14903757,\n",
       "       -0.3840043 ,  0.05018544, -0.05499632, -0.150933  ,  0.05669961,\n",
       "        0.4996005 , -0.02678811, -0.2627858 , -0.16920997, -0.11859377,\n",
       "        0.19333589, -0.01074175, -0.05574788,  0.41929665, -0.26151064,\n",
       "        0.25590292,  0.34211677,  0.1054531 , -0.00687985, -0.16779888,\n",
       "        0.03130335, -0.05452671,  0.0704404 ,  0.17898904, -0.34572747,\n",
       "       -0.22174072, -0.39247435, -0.15494153,  0.23106207,  0.10603652,\n",
       "        0.14512092,  0.2143693 , -0.13447766,  0.05398221, -0.08187675,\n",
       "        0.11334511,  0.01545186, -0.02413536,  0.12072697, -0.09430569,\n",
       "        0.14154156, -0.03885906, -0.14339   ,  0.39304015, -0.13630913,\n",
       "        0.035033  , -0.06954999, -0.13425104, -0.03108964,  0.07522734,\n",
       "        0.06269047, -0.04427013, -0.2469909 ,  0.06248191,  0.06584349,\n",
       "       -0.08349076,  0.05004467,  0.14113764, -0.2477111 ,  0.01721903,\n",
       "       -0.12226789,  0.07940459, -0.13129213, -0.15368631, -0.28004435],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors_model[\"Katze\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.52544963e-01,  2.56488323e-01,  2.62146950e-01,  1.96612179e-01,\n",
       "        2.39362642e-02, -2.29121178e-01,  1.81114152e-02,  1.67492196e-01,\n",
       "       -1.84928089e-01, -5.80801070e-02,  1.28630862e-01,  8.61339197e-02,\n",
       "       -2.29549274e-01,  4.30914432e-01, -3.94249484e-02,  1.52189806e-01,\n",
       "       -4.90663648e-01,  3.00991652e-03,  6.13174260e-01,  2.92929467e-02,\n",
       "       -1.00033090e-01,  1.50265153e-02,  8.77532586e-02, -2.19525263e-01,\n",
       "        1.44876376e-01,  5.37484651e-04, -5.65597266e-02, -8.94784629e-02,\n",
       "       -2.10487004e-02, -1.09548368e-01,  2.18051791e-01,  1.63616657e-01,\n",
       "       -2.17007458e-01,  8.87971297e-02,  3.89541477e-01, -2.07743734e-01,\n",
       "       -5.93353361e-02, -2.76203193e-02, -1.05253190e-01,  4.87749279e-02,\n",
       "        1.81017578e-01,  2.98786044e-01, -8.35407991e-03,  1.04766123e-01,\n",
       "       -2.53370441e-02,  1.65802881e-01, -1.18738793e-01,  4.38623518e-01,\n",
       "        2.48694092e-01,  2.32866913e-01,  5.86935505e-03,  1.22913845e-01,\n",
       "        7.34427795e-02, -6.29544631e-02,  6.36182427e-02,  1.15475826e-01,\n",
       "        5.66461915e-03, -1.03311405e-01, -2.63205767e-01,  2.42448822e-01,\n",
       "        4.30996008e-02, -8.92286152e-02,  2.83954024e-01,  1.70357868e-01,\n",
       "       -2.76803076e-01,  3.28347296e-01,  1.20871879e-01,  1.24516606e-01,\n",
       "       -4.32257652e-02,  1.57896608e-01,  3.63357924e-02, -3.87817651e-01,\n",
       "        3.93793024e-02, -1.12143733e-01, -5.85247315e-02,  2.45448342e-03,\n",
       "       -1.17364377e-01, -3.74917537e-02,  2.25062966e-01, -1.98893964e-01,\n",
       "       -4.69147712e-01,  1.52828932e-01,  3.55720222e-02, -2.33114585e-02,\n",
       "        2.54848510e-01,  1.06182769e-01,  1.51887074e-01, -8.50569904e-02,\n",
       "       -6.97330683e-02,  2.44348362e-01, -1.96227059e-01,  1.38582289e-01,\n",
       "        7.59335458e-02,  2.87197262e-01,  9.37106609e-02,  1.28021479e-01,\n",
       "       -1.07195891e-01,  1.28574729e-01,  5.97138423e-03,  5.58818057e-02,\n",
       "       -1.99939325e-01,  9.87252071e-02, -2.64811128e-01,  6.26143441e-02,\n",
       "       -2.15916727e-02,  1.13176517e-04, -2.18602210e-01, -2.60929346e-01,\n",
       "        3.54255199e-01,  1.89596027e-01, -1.20917663e-01, -2.58281022e-01,\n",
       "        3.03672194e-01,  1.97553068e-01,  3.45403075e-01,  2.90713683e-02,\n",
       "       -1.67768791e-01,  9.55959484e-02,  2.02555656e-01,  2.07814753e-01,\n",
       "       -9.70576480e-02, -1.70573324e-01, -1.40069481e-02, -1.96709275e-01,\n",
       "        3.94452453e-01,  4.29857932e-02,  2.02826306e-01,  1.62864357e-01,\n",
       "        1.03287518e-01, -4.08692323e-02,  2.28232983e-02,  5.23983575e-02,\n",
       "        1.94677278e-01,  1.52059615e-01, -2.15423182e-01, -1.00454673e-01,\n",
       "        2.68015116e-01,  1.50209386e-02,  1.23627074e-02,  1.48292696e-02,\n",
       "       -2.46281296e-01, -3.14790100e-01,  2.81556189e-01, -2.91884005e-01,\n",
       "        1.41986057e-01,  1.48179576e-01,  1.73412787e-03,  6.60692826e-02,\n",
       "       -1.97842810e-03, -3.85800675e-02, -3.13801058e-02, -5.71530387e-02,\n",
       "        1.32418334e-01,  1.28800705e-01, -3.47250104e-02,  3.00245911e-01,\n",
       "        1.58249676e-01, -6.86447173e-02,  2.79933333e-01,  1.75516516e-01,\n",
       "       -7.46675432e-02, -8.25696066e-02,  6.04895614e-02, -1.64742693e-01,\n",
       "        1.95082217e-01,  7.55526051e-02,  3.17169726e-01, -9.02808644e-03,\n",
       "        1.57749146e-01, -1.12747654e-01,  5.64321084e-03, -8.47596303e-02,\n",
       "        8.10890198e-02, -9.21660438e-02, -2.02943720e-02,  1.88154966e-01,\n",
       "       -3.64124835e-01,  2.71573037e-01, -5.07494260e-04, -2.31397226e-01,\n",
       "       -4.13752556e-01,  5.85177802e-02,  7.06390738e-02, -2.22202558e-02,\n",
       "        2.35997856e-01, -2.16676816e-01, -5.67695946e-02, -8.23834166e-02,\n",
       "        1.42712340e-01, -4.04349901e-02,  4.55709659e-02,  5.63924722e-02,\n",
       "        2.65141904e-01,  2.18442157e-01,  6.16271831e-02, -1.79592803e-01,\n",
       "       -3.05624992e-01,  6.96310550e-02, -4.27946560e-02, -2.31776565e-01,\n",
       "        1.41551346e-01,  1.89556237e-02,  7.29543343e-02,  1.73103303e-01,\n",
       "        1.52985036e-01,  4.58136916e-01, -3.05661820e-02, -5.86389266e-02,\n",
       "       -6.09457076e-01,  4.29830427e-04, -8.55976269e-02,  9.51435640e-02,\n",
       "        1.98122978e-01, -3.67603712e-02,  1.20967880e-01, -1.30672723e-01,\n",
       "        1.08955450e-01, -1.52157962e-01, -6.16989322e-02, -8.67521912e-02,\n",
       "        9.95491892e-02, -2.91103497e-02,  6.56223148e-02, -2.22020060e-01,\n",
       "       -2.50547796e-01,  1.38946116e-01,  7.95496479e-02,  2.19725698e-01,\n",
       "       -8.88043344e-02,  3.81296247e-01,  3.20036188e-02,  2.28061285e-02,\n",
       "       -3.97528522e-02,  1.47383317e-01,  1.70344979e-01, -5.33769354e-02,\n",
       "        1.27774790e-01, -3.03605683e-02, -6.95822835e-02,  1.80475101e-01,\n",
       "        5.00277340e-01,  6.13569543e-02, -2.19001621e-03,  1.69645384e-01,\n",
       "       -2.03674570e-01,  1.60682961e-01,  5.86663224e-02, -8.70502964e-02,\n",
       "        1.49847746e-01, -1.08584806e-01, -2.10791379e-01, -1.90031957e-02,\n",
       "       -3.70927192e-02, -1.00883961e-01, -5.51122380e-03, -5.67345396e-02,\n",
       "       -7.48194521e-03, -9.48528722e-02,  1.67635649e-01,  2.14221686e-01,\n",
       "        3.17937549e-04,  1.53612092e-01,  4.77397926e-02,  4.77398068e-01,\n",
       "        5.35902008e-02, -1.88913971e-01,  1.12777859e-01,  2.51273699e-02,\n",
       "       -2.09580600e-01, -3.06234330e-01,  9.28032305e-03, -4.32005748e-02,\n",
       "        2.17901573e-01, -1.29801482e-01,  2.42494300e-01, -3.99168909e-01,\n",
       "       -1.27609238e-01, -3.35497648e-01,  9.11227763e-02, -1.01492353e-01,\n",
       "        1.10086445e-02, -8.10088888e-02, -3.26881856e-01, -6.25217482e-02,\n",
       "        2.13383853e-01,  2.20910646e-02,  3.52650732e-01, -1.82508796e-01,\n",
       "        5.61190099e-02,  1.36802778e-01,  2.89021194e-01,  1.10328980e-01,\n",
       "        5.80303520e-02, -1.13568269e-01,  4.20772657e-02,  2.25720722e-02,\n",
       "        1.89306393e-01, -2.21322283e-01, -5.01951762e-03,  8.61672685e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors_model[\"Inkasso\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann Frau 0.8095551\n",
      "Mann Apfel 0.30760363\n",
      "Mann Banane 0.28847867\n",
      "Frau Mann 0.8095551\n",
      "Frau Apfel 0.26595286\n",
      "Frau Banane 0.31406382\n",
      "Apfel Mann 0.30760363\n",
      "Apfel Frau 0.26595286\n",
      "Apfel Banane 0.6604762\n",
      "Banane Mann 0.28847867\n",
      "Banane Frau 0.31406382\n",
      "Banane Apfel 0.6604762\n"
     ]
    }
   ],
   "source": [
    "words = [\"Mann\", \"Frau\", \"Apfel\", \"Banane\"]\n",
    "for token1 in words:\n",
    "    for token2 in words:     \n",
    "        if token1 != token2:\n",
    "            print(token1, token2, word_vectors_model.similarity(token1,token2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's the most similar word?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Katze', 0.8130383491516113),\n",
       " ('Vierbeiner', 0.807488203048706),\n",
       " ('Tier', 0.7901308536529541),\n",
       " ('Dackel', 0.7848663330078125),\n",
       " ('Frauchen', 0.7831077575683594),\n",
       " ('Schaeferhund', 0.7816431522369385),\n",
       " ('Herrchen', 0.7813007831573486),\n",
       " ('Huendin', 0.7660676836967468),\n",
       " ('Gassi_gehen', 0.7625339031219482),\n",
       " ('Mischlingshund', 0.7615839242935181),\n",
       " ('Hunde', 0.7571041584014893),\n",
       " ('Jagdhund', 0.7460682988166809),\n",
       " ('Mischling', 0.7409281134605408),\n",
       " ('Hunden', 0.7333001494407654),\n",
       " ('ausgebuexten', 0.7294281125068665),\n",
       " ('Gassigehen', 0.7249583601951599),\n",
       " ('Hamster', 0.7240623235702515),\n",
       " ('bellend', 0.7238216996192932),\n",
       " ('Papagei', 0.7225003242492676),\n",
       " ('Cockerspaniel', 0.7203546166419983)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors_model.most_similar(\"Hund\", topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Kuerbis', 0.7526000738143921),\n",
       " ('Gurke', 0.7188601493835449),\n",
       " ('Zitrone', 0.7182591557502747),\n",
       " ('Wurst', 0.7072211503982544),\n",
       " ('Kartoffel', 0.7019344568252563),\n",
       " ('Kohlrabi', 0.6948261260986328),\n",
       " ('Erdbeere', 0.6946195363998413),\n",
       " ('Aepfeln', 0.6938279271125793),\n",
       " ('Speck', 0.688808798789978),\n",
       " ('Himbeeren', 0.687086820602417),\n",
       " ('Spitzkohl', 0.6857706308364868),\n",
       " ('Birne', 0.6840704083442688),\n",
       " ('Tomate', 0.6834304332733154),\n",
       " ('Pfirsich', 0.683165431022644),\n",
       " ('Bohnen', 0.6814666986465454),\n",
       " ('Moehre', 0.6810375452041626),\n",
       " ('Aepfel', 0.6807883977890015),\n",
       " ('Kraut', 0.6775155067443848),\n",
       " ('Wassermelone', 0.6771656274795532),\n",
       " ('Paprika', 0.6768082976341248)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors_model.most_similar(\"Apfel\", topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some math with word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Koenig - Mann + Frau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Koenigin', 0.7524535655975342),\n",
       " ('Prinzessin', 0.71452796459198),\n",
       " ('Prinz', 0.6881615519523621),\n",
       " ('Jungschuetzenkoenigin', 0.6740391254425049),\n",
       " ('Majestaet', 0.659064769744873)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = [\"Frau\", \"Koenig\"]\n",
    "negative = [\"Mann\"]\n",
    "word_vectors_model.most_similar(positive=positive, negative=negative, topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putin - Rusland + Deutschland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bundeskanzlerin', 0.6233305931091309),\n",
       " ('Kanzlerin_Merkel', 0.6167038679122925),\n",
       " ('Angela_Merkel', 0.6104297637939453),\n",
       " ('Kanzlerin', 0.6102859377861023),\n",
       " ('Merkel', 0.5968186855316162)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = [\"Putin\", \"Deutschland\"]\n",
    "negative = [\"Russland\"]\n",
    "word_vectors_model.most_similar(positive=positive, negative=negative, topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out German wordvectors from Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.wrappers import FastText\n",
    "word_vectors_model = FastText.load_fasttext_format('cc.de.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00705658,  0.03665943, -0.04904251,  0.03038029, -0.05216099,\n",
       "        0.07476059,  0.04375604, -0.0576677 , -0.00598645,  0.00954182,\n",
       "       -0.02619467,  0.03105956, -0.00193281,  0.04072258,  0.05409295,\n",
       "        0.01081038,  0.02409723,  0.03717486, -0.12060858, -0.04739867,\n",
       "        0.008459  , -0.03755536,  0.03592665,  0.01946772, -0.09275625,\n",
       "        0.0206445 , -0.00370327,  0.08105088, -0.02166642, -0.06563529,\n",
       "       -0.0382905 , -0.02920803,  0.01238743,  0.01038295,  0.10285275,\n",
       "        0.07828199, -0.05679911, -0.00513924,  0.07510853, -0.04531677,\n",
       "        0.03413609,  0.11717834, -0.02007757, -0.01422268, -0.01368631,\n",
       "        0.03565939, -0.11995326, -0.0227239 ,  0.02291417, -0.02815491,\n",
       "       -0.02096579, -0.01028913, -0.01171383,  0.05634379, -0.01442095,\n",
       "       -0.02910704, -0.03573475, -0.06545392,  0.00390892, -0.02880078,\n",
       "       -0.01523009,  0.01006212,  0.03027238,  0.14800395, -0.05113512,\n",
       "       -0.01366111,  0.0897688 , -0.04535784,  0.03976589,  0.01681696,\n",
       "        0.05233503, -0.07541899, -0.05674038,  0.00528442, -0.00265266,\n",
       "       -0.07515596,  0.10170212,  0.02158847, -0.03957824, -0.01172988,\n",
       "       -0.06204252, -0.02331112, -0.12051297,  0.03875609, -0.00320276,\n",
       "        0.02558623, -0.04833636, -0.00644625, -0.00153983,  0.09709201,\n",
       "        0.09339132,  0.03638883,  0.03132446,  0.01938367,  0.07824042,\n",
       "        0.0366203 ,  0.00266704,  0.07671657, -0.03934296,  0.05447573,\n",
       "       -0.05832769,  0.02383921, -0.01481631, -0.06049696, -0.01800744,\n",
       "       -0.0829214 ,  0.0826861 ,  0.01085551, -0.10192933, -0.07553982,\n",
       "        0.00386302,  0.04741725, -0.0444618 ,  0.01604384,  0.1037666 ,\n",
       "       -0.03378014,  0.10366002, -0.16330434,  0.00866504, -0.04527508,\n",
       "       -0.08671819,  0.02667002,  0.10420776, -0.07227637,  0.06742482,\n",
       "        0.09231097,  0.039426  , -0.09896017,  0.00906232, -0.02274334,\n",
       "       -0.12581614,  0.00095053, -0.02028544,  0.02025509,  0.06491902,\n",
       "        0.0104788 ,  0.07876398,  0.00217779,  0.02103569, -0.04074227,\n",
       "        0.02858072, -0.03023321,  0.05797382, -0.01932833, -0.00116118,\n",
       "        0.02869871, -0.02868076,  0.01585878, -0.02120481, -0.00435577,\n",
       "       -0.04910092,  0.14916691,  0.02870997,  0.02673208,  0.04024534,\n",
       "        0.1108178 ,  0.05339153, -0.06500547,  0.0585968 , -0.0665459 ,\n",
       "       -0.07401817, -0.05434644,  0.05484679,  0.07249691,  0.08516506,\n",
       "        0.0412283 ,  0.03090147, -0.04927894, -0.00409939,  0.03042361,\n",
       "       -0.06291544,  0.03032253, -0.04714081,  0.00472834,  0.08938576,\n",
       "       -0.00289531,  0.03277313, -0.040743  ,  0.02628798,  0.10193469,\n",
       "        0.09114644,  0.06373779, -0.07244843, -0.02998066,  0.05648164,\n",
       "       -0.01883798,  0.04927912,  0.05479369,  0.03324885, -0.07510038,\n",
       "       -0.07131609, -0.04940774, -0.09981048,  0.08031541,  0.13142648,\n",
       "        0.04617924,  0.02652885, -0.05722576,  0.03525846,  0.00613538,\n",
       "        0.07406989, -0.06471746,  0.10190168, -0.05460991,  0.03044861,\n",
       "       -0.02672008,  0.07509437,  0.05752053, -0.03061411,  0.02278423,\n",
       "        0.03434619, -0.07979342, -0.01488099, -0.05159345,  0.07302765,\n",
       "       -0.0375459 , -0.04152999, -0.00191082, -0.02754092,  0.01634421,\n",
       "       -0.01666856,  0.03824262,  0.0087021 ,  0.07619224,  0.05923042,\n",
       "       -0.01404024,  0.02084912,  0.04286651,  0.07995453,  0.02772016,\n",
       "        0.0687279 , -0.1264608 , -0.08600285,  0.00613145,  0.0772052 ,\n",
       "        0.04404363,  0.02181005,  0.00316212,  0.08967844,  0.04723576,\n",
       "        0.10103716,  0.11941247,  0.11952423, -0.0493014 ,  0.04411491,\n",
       "        0.03078252, -0.00206495, -0.04179587, -0.04161734, -0.0346924 ,\n",
       "       -0.0608398 , -0.04935927,  0.0609947 ,  0.00659093,  0.00675696,\n",
       "        0.01526661,  0.00561003, -0.00166845,  0.07613614,  0.03281366,\n",
       "        0.03687913, -0.03864361, -0.00496422, -0.04458604, -0.00169327,\n",
       "        0.00208818, -0.00599684, -0.01557022, -0.07897381,  0.07032424,\n",
       "        0.04168858,  0.03796367, -0.14374688, -0.04669879,  0.00791449,\n",
       "       -0.02077932,  0.139224  ,  0.07433571, -0.15944067,  0.04034874,\n",
       "       -0.16835007,  0.01515236, -0.03258567, -0.00745193, -0.040608  ,\n",
       "        0.04612036,  0.11862068,  0.0129211 , -0.00060535,  0.05582931,\n",
       "       -0.02853853,  0.03811673, -0.01799109,  0.00095913,  0.09655648,\n",
       "       -0.04608829,  0.11472737, -0.09156533,  0.00666003, -0.0596446 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors_model[\"Katze\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Vierbeiner', 0.8140769004821777),\n",
       " ('Hunde', 0.792273998260498),\n",
       " ('Hunden', 0.7635980844497681),\n",
       " ('Hund.', 0.7381591796875),\n",
       " ('Herrchen', 0.7317228317260742),\n",
       " ('Katze', 0.7219496369361877),\n",
       " ('Familienhund', 0.7209774851799011),\n",
       " ('Nachbarshund', 0.7175627946853638),\n",
       " ('Nachbarhund', 0.716743528842926),\n",
       " ('Hundes', 0.7121168971061707),\n",
       " ('Junghund', 0.7093837261199951),\n",
       " ('Welpe', 0.7068514823913574),\n",
       " ('Dackel', 0.7014358043670654),\n",
       " ('Hundefreund', 0.6981956958770752),\n",
       " ('hund', 0.6962772607803345),\n",
       " ('Hundekumpel', 0.6933536529541016),\n",
       " ('Hundebesitzer', 0.6889547109603882),\n",
       " ('Frauchen', 0.6885875463485718),\n",
       " ('Einzelhund', 0.684305727481842),\n",
       " ('Hundchen', 0.6801247000694275)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors_model.most_similar(\"Hund\", topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Koenigin', 0.52174973487854),\n",
       " ('Koenigs', 0.5118163228034973),\n",
       " ('Alexandra', 0.5115703344345093),\n",
       " ('Ursula', 0.5099889039993286),\n",
       " ('Christa', 0.504902720451355)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = [\"Frau\", \"Koenig\"]\n",
    "negative = [\"Mann\"]\n",
    "word_vectors_model.most_similar(positive=positive, negative=negative, topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Merkel', 0.6383850574493408),\n",
       " ('Obama', 0.5623136758804321),\n",
       " ('Erdogan', 0.559893012046814),\n",
       " ('Kanzlerin', 0.5595794320106506),\n",
       " ('Gauck', 0.5471944808959961)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = [\"Putin\", \"Deutschland\"]\n",
    "negative = [\"Russland\"]\n",
    "word_vectors_model.most_similar(positive=positive, negative=negative, topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "The default German wordvec model from spacy is not very convincing. Wordvectors from\n",
    "https://devmount.github.io/GermanWordEmbeddings/ or from https://fasttext.cc/ seem more reliable. For quick experiments the first one is more suitable, since the fasttext model is extremely large (7 Gb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
